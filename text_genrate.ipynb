{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "AML3304 Software tools and emerging Technologies\n",
        "Final project code"
      ],
      "metadata": {
        "id": "Yv8o_PdXC37i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBL1KfRTjZJx",
        "outputId": "af6f3ff6-290b-4c6c-a396-224deb369f27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dTLYub9YjaQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VWNGLq3ox8_H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x0QGInUcx_7z"
      },
      "outputs": [],
      "source": [
        "\n",
        "# load the text data\n",
        "with open('/content/drive/MyDrive/New folder/145-0.txt', 'r') as f:\n",
        "    text = f.read().lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Yg0-c1acyIXI"
      },
      "outputs": [],
      "source": [
        "# create a mapping of characters to integers\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V6lGKBh_yTEV"
      },
      "outputs": [],
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, len(text) - seq_length, 1):\n",
        "    seq_in = text[i:i + seq_length]\n",
        "    seq_out = text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1R1CAWg3yVSZ"
      },
      "outputs": [],
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8UgY3W9ByktA"
      },
      "outputs": [],
      "source": [
        "# normalize the input data\n",
        "X = X / float(len(chars))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JfzUllMlyo3d"
      },
      "outputs": [],
      "source": [
        "# one hot encode the output variable\n",
        "y = tf.keras.utils.to_categorical(dataY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2vyAlGzjyr0m"
      },
      "outputs": [],
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRs-9VbvC3xh",
        "outputId": "6cb6bd56-a056-4266-c1e1-a41eacc4e615"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               66560     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 80)                10320     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 76880 (300.31 KB)\n",
            "Trainable params: 76880 (300.31 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7udUZSwyu_M",
        "outputId": "30dd391e-3e16-41b5-9bbf-99036eceed29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "14056/14056 [==============================] - 3831s 273ms/step - loss: 2.7804\n",
            "Epoch 2/6\n",
            "14056/14056 [==============================] - 3810s 271ms/step - loss: 2.5990\n",
            "Epoch 3/6\n",
            "14056/14056 [==============================] - 3789s 270ms/step - loss: 2.4766\n",
            "Epoch 4/6\n",
            "14056/14056 [==============================] - 3808s 271ms/step - loss: 2.3930\n",
            "Epoch 5/6\n",
            "14056/14056 [==============================] - 3833s 273ms/step - loss: 2.3336\n",
            "Epoch 6/6\n",
            "14056/14056 [==============================] - 3857s 274ms/step - loss: 2.2891\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8e50ff8190>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# train the model\n",
        "model.fit(X, y, epochs=6, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "pkl.dump(model, open('/content/drive/MyDrive/New folder/final_model1.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "skm4OqJKbe-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate text\n",
        "start_index = random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start_index]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "for i in range(1000):\n",
        "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(len(chars))\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdGoTxzv_1UE",
        "outputId": "141f5ee8-6749-48a4-937d-a0fcfcd1a4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" observed solomon, his sister’s question having\n",
            "drawn no answer.\n",
            "\n",
            "“what, blue-coat land?” said mrs. w \"\n",
            "anled was a feet th the hasd and toeer the wese and the saee to her aod the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer the wese an an and the saee to her aod toeer th"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WfsLFJcANhA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}